{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# caution: path[0] is reserved for script path (or '' in REPL)\n",
    "sys.path.insert(1, 'D:\\\\Sparta\\\\final_project\\\\data210-final-project\\\\Scripts')\n",
    "import sqlalchemy as db\n",
    "from sqlalchemy import create_engine, Table, Column, Integer, String, MetaData, Date, ForeignKey, Boolean\n",
    "from sqlalchemy import text\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "#load_dotenv()  # Load environment variables from .env file\n",
    "#db_password = os.getenv(\"DB_PASSWORD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"mssql+pyodbc://admin:spartaglobal@sparta-global.cjxe5m4vhofo.eu-west-2.rds.amazonaws.com:1433/project?driver=ODBC+Driver+17+for+SQL+Server\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if database_exists(engine.url) == False:\n",
    "        create_database(engine.url)\n",
    "except:\n",
    "    create_database(engine.url)\n",
    "\n",
    "# drop all tables\n",
    "metadata = db.MetaData()\n",
    "metadata.reflect(bind=engine)\n",
    "metadata.drop_all(bind=engine)\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    metadata = MetaData()\n",
    "\n",
    "    #define tables\n",
    "    table_name = 'Recruiters'\n",
    "    recruiters_table = Table (table_name, metadata,\n",
    "                            Column('recruiter_id', Integer, primary_key=True, autoincrement=True),\n",
    "                            Column('recruiter_name', String)\n",
    "                            )\n",
    "\n",
    "    table_name = 'Applicants'\n",
    "    applicants_table = Table(table_name, metadata,\n",
    "                        Column('applicant_id', String(50), primary_key=True),\n",
    "                        Column('name', String),\n",
    "                        Column('gender', String),\n",
    "                        Column('dob', Date),\n",
    "                        Column('email', String),\n",
    "                        Column('phone_number', String),\n",
    "                        Column('uni', String),\n",
    "                        Column('degree', String),\n",
    "                        Column('invited_date', Date),\n",
    "                        Column('recruiter_id', Integer, ForeignKey('Recruiters.recruiter_id'))                  \n",
    "                        )\n",
    "\n",
    "    # table_name = 'Location'\n",
    "    # location_table = Table (table_name, metadata,\n",
    "    #                         Column('location_id', Integer, primary_key=True, autoincrement=True),\n",
    "    #                         Column('applicant_id', String(50), ForeignKey('Applicants.applicant_id')),\n",
    "    #                         Column('address', String),\n",
    "    #                         Column('postcode', String),\n",
    "    #                         Column('city', String)\n",
    "    #                         )\n",
    "\n",
    "    table_name = 'Academy_Locations'\n",
    "    Academy_location_table = Table (table_name, metadata,\n",
    "                        Column('academy_location_id', Integer, primary_key=True, autoincrement=True),\n",
    "                        Column('location_name', String)\n",
    "                        )\n",
    "\n",
    "    table_name = 'Talent'\n",
    "    talent_table = Table(table_name, metadata,\n",
    "                                Column('talent_id', Integer, primary_key=True,autoincrement=True),\n",
    "                                Column('json_key', Integer, unique=True, nullable=True),\n",
    "                                Column('applicant_id', String(50), ForeignKey('Applicants.applicant_id'), unique=True),\n",
    "                                Column('date', Date, nullable=True),\n",
    "                                Column('self_development', Boolean),\n",
    "                                Column('financial_support_self', Boolean),\n",
    "                                Column('result', Integer),\n",
    "                                Column('course_interest', String),\n",
    "                                Column('psychometric_result', Integer),\n",
    "                                Column('presentation_result', Integer),\n",
    "                                Column('geo_flex', Boolean),\n",
    "                                Column('academy_location_id', Integer, ForeignKey('Academy_Locations.academy_location_id'))\n",
    "                                )\n",
    "\n",
    "    table_name = 'Strengths'\n",
    "    strengths_table = Table(table_name, metadata,\n",
    "                        Column('strength_id', Integer, primary_key=True),\n",
    "                        Column('strength', String(30), unique=True, nullable=False)\n",
    "                        )\n",
    "\n",
    "    table_name = 'Weaknesses'\n",
    "    strengths_table = Table(table_name, metadata,\n",
    "                        Column('weakness_id', Integer, primary_key=True),\n",
    "                        Column('weakness', String(30), unique=True, nullable=False)\n",
    "                        )\n",
    "\n",
    "    table_name = 'Strengths_Junction'\n",
    "    strengths_junction = Table(table_name,metadata,\n",
    "                            Column('json_key', Integer, ForeignKey('Talent.json_key')),\n",
    "                            Column('strength_id', Integer, ForeignKey('Strengths.strength_id'))\n",
    "                            )\n",
    "\n",
    "    table_name = 'Weaknesses_Junction'\n",
    "    weaknesses_junction = Table(table_name,metadata,\n",
    "                            Column('json_key', Integer, ForeignKey('Talent.json_key')),\n",
    "                            Column('weakness_id', Integer)\n",
    "                            )\n",
    "\n",
    "    table_name = 'Tech_Self_Scores'\n",
    "    tech_table = Table(table_name, metadata,\n",
    "                    Column('tech_id', Integer, primary_key=True, autoincrement=True),\n",
    "                    Column('tech_name', String(50), unique=True, nullable=False)\n",
    "                    )\n",
    "\n",
    "    table_name = 'Tech_Junction'\n",
    "    tech_junction_table = Table(table_name, metadata,\n",
    "                                Column('tech_id', Integer, ForeignKey(\"Tech_Self_Scores\")),\n",
    "                                Column('json_key', Integer, ForeignKey('Talent.json_key')),\n",
    "                                Column('score', Integer, nullable=False)\n",
    "                                )\n",
    "\n",
    "    table_name = 'Trainers'\n",
    "    trainers_table = Table(table_name, metadata,\n",
    "                            Column('trainer_id', String(30), primary_key=True),\n",
    "                            Column('trainer', String(50), nullable=False, unique=True)\n",
    "                            )\n",
    "\n",
    "    table_name = 'Courses'\n",
    "    courses_table = Table(table_name, metadata,\n",
    "                        Column('course_id', String(30), primary_key=True),\n",
    "                        Column('course_name', String, nullable=False)\n",
    "                        )\n",
    "\n",
    "    table_name = 'Spartans'\n",
    "    spartans_table = Table(table_name, metadata,\n",
    "                        Column('spartan_id', Integer, primary_key=True,autoincrement=True),\n",
    "                        Column('json_key', Integer, ForeignKey('Talent.json_key'), unique=True, nullable=True),\n",
    "                        Column('trainer_id', String(30), ForeignKey('Trainers.trainer_id'), nullable=False),\n",
    "                        Column('course_id', String(30), ForeignKey('Courses.course_id'), nullable=False)\n",
    "                        )\n",
    "\n",
    "    table_name = 'Behaviours'\n",
    "    behaviours_table = Table(table_name, metadata, \n",
    "                            Column('behaviour_id', Integer, primary_key=True, autoincrement=True), \n",
    "                            Column('spartan_id', Integer, ForeignKey('Spartans.spartan_id')), \n",
    "                            Column('week_number', Integer, nullable=False), \n",
    "                            Column('analytic', Integer), \n",
    "                            Column('independent', Integer), \n",
    "                            Column('imaginative', Integer), \n",
    "                            Column('studious', Integer), \n",
    "                            Column('professional', Integer), \n",
    "                            Column('determined', Integer)\n",
    "                            )\n",
    "\n",
    "    metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Applicant_cleaning' from 'D:\\\\Sparta\\\\final_project\\\\data210-final-project\\\\Scripts\\\\Applicant_cleaning.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import TalentTable\n",
    "importlib.reload(TalentTable)\n",
    "import Applicant_cleaning\n",
    "importlib.reload(Applicant_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Technologies' from 'D:\\\\Sparta\\\\final_project\\\\data210-final-project\\\\Scripts\\\\Technologies.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import json_strengths_weaknesses\n",
    "importlib.reload(json_strengths_weaknesses)\n",
    "import Technologies\n",
    "importlib.reload(Technologies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  json_key   weaknesses\n",
      "0    10383   Distracted\n",
      "1    10383    Impulsive\n",
      "2    10383  Introverted\n",
      "3    10384  Overbearing\n",
      "4    10384       Chatty\n"
     ]
    }
   ],
   "source": [
    "df_temp = json_strengths_weaknesses.pull_json_from_s3('data-eng-210-final-project', 'Talent')\n",
    "df_strengths, df_strengths_junction = json_strengths_weaknesses.generate_strengths(df_temp)\n",
    "df_weaknesses, df_weaknesses_junction = json_strengths_weaknesses.generate_weaknesses(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tech_self_scores, df_tech_junction = Technologies.technologies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_talent, df_academy_locations = TalentTable.Talent()\n",
    "df_talent['geo_flex'] = df_talent['geo_flex'].map({'Yes': True, 'No':False})\n",
    "df_talent['financial_support_self'] = df_talent['financial_support_self'].map({'Yes': True, 'No':False})\n",
    "df_talent['self_development'] = df_talent['self_development'].map({'Yes': True, 'No':False})\n",
    "df_talent['result'] = df_talent['result'].map({'Pass': 1, 'Fail':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caching talent tables because they take ages, dont use normally\n",
    "with open('df_strengths.csv', 'w') as file:\n",
    "    df_strengths.to_csv(file)\n",
    "with open('df_weaknesses.csv', 'w') as file:\n",
    "    df_weaknesses.to_csv(file)\n",
    "with open('df_strengths_junction.csv', 'w') as file:\n",
    "    df_strengths_junction.to_csv(file)\n",
    "with open('df_weaknesses_junction.csv', 'w') as file:\n",
    "    df_weaknesses_junction.to_csv(file)\n",
    "with open('df_talent.csv', 'w') as file:\n",
    "    df_talent.to_csv(file)\n",
    "with open('df_academy_locations.csv', 'w') as file:\n",
    "    df_academy_locations.to_csv(file)\n",
    "with open('df_tech_self_scores.csv', 'w') as file:\n",
    "    df_tech_self_scores.to_csv(file)\n",
    "with open('df_tech_junction.csv', 'w') as file:\n",
    "    df_tech_junction.to_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load from cached csvs, careful with losing data types\n",
    "df_strengths = pd.read_csv('df_strengths.csv',index_col=0)\n",
    "df_strengths_junction = pd.read_csv('df_strengths_junction.csv',index_col=0)\n",
    "df_weaknesses = pd.read_csv('df_weaknesses.csv',index_col=0)\n",
    "df_weaknesses_junction = pd.read_csv('df_weaknesses_junction.csv',index_col=0)\n",
    "df_tech_self_scores = pd.read_csv('df_tech_self_scores.csv',index_col=0)\n",
    "df_tech_junction = pd.read_csv('df_tech_junction.csv',index_col=0)\n",
    "df_talent = pd.read_csv('df_talent.csv',index_col=0)\n",
    "df_academy_locations = pd.read_csv('df_academy_locations.csv',index_col=0)\n",
    "df_talent = df_talent.rename(columns={'Date':'date'})\n",
    "df_talent.date = pd.to_datetime(df_talent.date)\n",
    "df_talent_test = df_talent = pd.read_csv('df_talent.csv',index_col=0)\n",
    "df_academy_locations = pd.read_csv('df_academy_locations.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_applicants, df_location, df_recruiters = Applicant_cleaning.process_locations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There's multiple jsons of the same person on the same date - this condenses them down and merges information\n",
    "#(e.g. some duplicates have some of the sparta day scores some don't, this fixes that mostly)\n",
    "df_talent = df_talent.groupby(['applicant_id'], as_index=False).first()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Debugging duplicate names\n",
    "#df_talent[df_talent.duplicated(subset=['name'],keep=False)].sort_values(\"name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>applicant_id</th>\n",
       "      <th>json_key</th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>self_development</th>\n",
       "      <th>financial_support_self</th>\n",
       "      <th>result</th>\n",
       "      <th>course_interest</th>\n",
       "      <th>psychometric_result</th>\n",
       "      <th>presentation_result</th>\n",
       "      <th>geo_flex</th>\n",
       "      <th>academy_location_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [applicant_id, json_key, name, date, self_development, financial_support_self, result, course_interest, psychometric_result, presentation_result, geo_flex, academy_location_id]\n",
       "Index: []"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Debugging duplicate ids\n",
    "#df_talent[df_talent.duplicated(subset=['applicant_id'],keep=False)].sort_values(\"applicant_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>applicant_id</th>\n",
       "      <th>json_key</th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>self_development</th>\n",
       "      <th>financial_support_self</th>\n",
       "      <th>result</th>\n",
       "      <th>course_interest</th>\n",
       "      <th>psychometric_result</th>\n",
       "      <th>presentation_result</th>\n",
       "      <th>geo_flex</th>\n",
       "      <th>academy_location_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aarikapreist20190508</td>\n",
       "      <td>12361.0</td>\n",
       "      <td>Aarika Preist</td>\n",
       "      <td>2019-05-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>57.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abbeballard20190221</td>\n",
       "      <td>11619.0</td>\n",
       "      <td>Abbe Ballard</td>\n",
       "      <td>2019-02-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data</td>\n",
       "      <td>60.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abbehanny20190326</td>\n",
       "      <td>11982.0</td>\n",
       "      <td>Abbe Hanny</td>\n",
       "      <td>2019-03-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data</td>\n",
       "      <td>60.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abbieclifton20190122</td>\n",
       "      <td>11770.0</td>\n",
       "      <td>Abbie Clifton</td>\n",
       "      <td>2019-01-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>61.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abbimulvihill20191106</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>2019-11-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>48.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4429</th>\n",
       "      <td>zondababbidge20190307</td>\n",
       "      <td>12136.0</td>\n",
       "      <td>Zonda Babbidge</td>\n",
       "      <td>2019-03-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Business</td>\n",
       "      <td>58.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4430</th>\n",
       "      <td>zondrafippe20190917</td>\n",
       "      <td>13113.0</td>\n",
       "      <td>Zondra Fippe</td>\n",
       "      <td>2019-09-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Business</td>\n",
       "      <td>60.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4431</th>\n",
       "      <td>zondralindgren20191016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>2019-10-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>48.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4432</th>\n",
       "      <td>zorahgrasser20190919</td>\n",
       "      <td>12975.0</td>\n",
       "      <td>Zorah Grasser</td>\n",
       "      <td>2019-09-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>56.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4433</th>\n",
       "      <td>zsazsarounsefull20190716</td>\n",
       "      <td>10705.0</td>\n",
       "      <td>Zsa Zsa Rounsefull</td>\n",
       "      <td>2019-07-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data</td>\n",
       "      <td>61.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4434 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  applicant_id  json_key                name       date   \n",
       "0         aarikapreist20190508   12361.0       Aarika Preist 2019-05-08  \\\n",
       "1          abbeballard20190221   11619.0        Abbe Ballard 2019-02-21   \n",
       "2            abbehanny20190326   11982.0          Abbe Hanny 2019-03-26   \n",
       "3         abbieclifton20190122   11770.0       Abbie Clifton 2019-01-22   \n",
       "4        abbimulvihill20191106       NaN                None 2019-11-06   \n",
       "...                        ...       ...                 ...        ...   \n",
       "4429     zondababbidge20190307   12136.0      Zonda Babbidge 2019-03-07   \n",
       "4430       zondrafippe20190917   13113.0        Zondra Fippe 2019-09-17   \n",
       "4431    zondralindgren20191016       NaN                None 2019-10-16   \n",
       "4432      zorahgrasser20190919   12975.0       Zorah Grasser 2019-09-19   \n",
       "4433  zsazsarounsefull20190716   10705.0  Zsa Zsa Rounsefull 2019-07-16   \n",
       "\n",
       "      self_development  financial_support_self  result course_interest   \n",
       "0                  NaN                     NaN     NaN     Engineering  \\\n",
       "1                  NaN                     NaN     NaN            Data   \n",
       "2                  NaN                     NaN     NaN            Data   \n",
       "3                  NaN                     NaN     NaN     Engineering   \n",
       "4                  NaN                     NaN     NaN            None   \n",
       "...                ...                     ...     ...             ...   \n",
       "4429               NaN                     NaN     NaN        Business   \n",
       "4430               NaN                     NaN     NaN        Business   \n",
       "4431               NaN                     NaN     NaN            None   \n",
       "4432               NaN                     NaN     NaN     Engineering   \n",
       "4433               NaN                     NaN     NaN            Data   \n",
       "\n",
       "      psychometric_result  presentation_result  geo_flex  academy_location_id  \n",
       "0                    57.0                 16.0       NaN                    2  \n",
       "1                    60.0                 20.0       NaN                    1  \n",
       "2                    60.0                 23.0       NaN                    2  \n",
       "3                    61.0                 23.0       NaN                    2  \n",
       "4                    48.0                 17.0       NaN                    2  \n",
       "...                   ...                  ...       ...                  ...  \n",
       "4429                 58.0                 19.0       NaN                    1  \n",
       "4430                 60.0                 15.0       NaN                    2  \n",
       "4431                 48.0                 19.0       NaN                    2  \n",
       "4432                 56.0                 26.0       NaN                    1  \n",
       "4433                 61.0                 20.0       NaN                    2  \n",
       "\n",
       "[4434 rows x 12 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_talent.drop_duplicates(subset=['applicant_id','course_interest','psychometric_result','presentation_result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "applicant_id                      object\n",
       "json_key                         float64\n",
       "name                              object\n",
       "date                      datetime64[ns]\n",
       "self_development                 float64\n",
       "financial_support_self           float64\n",
       "result                           float64\n",
       "course_interest                   object\n",
       "psychometric_result              float64\n",
       "presentation_result              float64\n",
       "geo_flex                         float64\n",
       "academy_location_id                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_talent.date = pd.to_datetime(df_talent.date)\n",
    "df_talent.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                                                Fidel Norval\n",
      "gender                                                      Male\n",
      "dob                                          1996-11-16 00:00:00\n",
      "email                                       fnorval3a@ebay.co.uk\n",
      "phone_number                                    +44-725-693-5614\n",
      "uni             Courtauld Institute of Art, University of London\n",
      "degree                                                       2:2\n",
      "invited_date                                 2019-06-19 00:00:00\n",
      "iddate                                                  20190619\n",
      "applicant_id                                 fidelnorval20190619\n",
      "recruiter_id                                                   8\n",
      "Name: 118, dtype: object\n",
      "             applicant_id  json_key          name date  self_development   \n",
      "1579  fidelnorval20190719   11082.0  Fidel Norval  NaT               NaN  \\\n",
      "\n",
      "      financial_support_self  result course_interest  psychometric_result   \n",
      "1579                     NaN     NaN     Engineering                  NaN  \\\n",
      "\n",
      "      presentation_result  geo_flex  academy_location_id  \n",
      "1579                  NaN       NaN                    0  \n"
     ]
    }
   ],
   "source": [
    "#Method to add the applicant ID from Applicants to Talents by matching nearest data\n",
    "def addApplicantIDToTalent(applicant_record):\n",
    "     if(pd.isnull(applicant_record['invited_date'])):\n",
    "          return\n",
    "     result = df_talent[(df_talent['name'].str.lower() == applicant_record['name'].lower()) & ((df_talent['date'].isnull()) | (df_talent['date'] >= applicant_record['invited_date']))].sort_values(by='date',axis=0,ascending=True)\n",
    "     if (applicant_record['name'].lower() == \"fidel norval\"):\n",
    "          print(applicant_record)\n",
    "          print(result)\n",
    "     if not result.empty:\n",
    "          df_talent.at[result.index[0],'applicant_id'] = applicant_record['applicant_id']\n",
    "          #print(talent_record['json_key'])\n",
    "          #print(result.index[0])df_talent\n",
    "#Do for every row in Applicant\n",
    "for index, row in df_applicants.iterrows():\n",
    "    addApplicantIDToTalent(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>applicant_id</th>\n",
       "      <th>json_key</th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>self_development</th>\n",
       "      <th>financial_support_self</th>\n",
       "      <th>result</th>\n",
       "      <th>course_interest</th>\n",
       "      <th>psychometric_result</th>\n",
       "      <th>presentation_result</th>\n",
       "      <th>geo_flex</th>\n",
       "      <th>academy_location_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abbimulvihill20191106</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>2019-11-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>48.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>abdulnail20190917</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>2019-09-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>52.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>abeuknightsbridge20190703</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>2019-07-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>65.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>abnerdevo20191024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>2019-10-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>36.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>abrahanbiggerdike20191030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>2019-10-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>48.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4106</th>\n",
       "      <td>yumadowry20190502</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>2019-05-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>48.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4108</th>\n",
       "      <td>yvettehammerberg20190226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>2019-02-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>49.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4121</th>\n",
       "      <td>zebadiahrollins20190926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>2019-09-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>58.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4123</th>\n",
       "      <td>zechariahsalzberger20190117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>2019-01-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>47.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4131</th>\n",
       "      <td>zondralindgren20191016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>2019-10-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>48.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1061 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     applicant_id  json_key  name       date   \n",
       "4           abbimulvihill20191106       NaN  None 2019-11-06  \\\n",
       "9               abdulnail20190917       NaN  None 2019-09-17   \n",
       "13      abeuknightsbridge20190703       NaN  None 2019-07-03   \n",
       "17              abnerdevo20191024       NaN  None 2019-10-24   \n",
       "19      abrahanbiggerdike20191030       NaN  None 2019-10-30   \n",
       "...                           ...       ...   ...        ...   \n",
       "4106            yumadowry20190502       NaN  None 2019-05-02   \n",
       "4108     yvettehammerberg20190226       NaN  None 2019-02-26   \n",
       "4121      zebadiahrollins20190926       NaN  None 2019-09-26   \n",
       "4123  zechariahsalzberger20190117       NaN  None 2019-01-17   \n",
       "4131       zondralindgren20191016       NaN  None 2019-10-16   \n",
       "\n",
       "      self_development  financial_support_self  result course_interest   \n",
       "4                  NaN                     NaN     NaN            None  \\\n",
       "9                  NaN                     NaN     NaN            None   \n",
       "13                 NaN                     NaN     NaN            None   \n",
       "17                 NaN                     NaN     NaN            None   \n",
       "19                 NaN                     NaN     NaN            None   \n",
       "...                ...                     ...     ...             ...   \n",
       "4106               NaN                     NaN     NaN            None   \n",
       "4108               NaN                     NaN     NaN            None   \n",
       "4121               NaN                     NaN     NaN            None   \n",
       "4123               NaN                     NaN     NaN            None   \n",
       "4131               NaN                     NaN     NaN            None   \n",
       "\n",
       "      psychometric_result  presentation_result  geo_flex  academy_location_id  \n",
       "4                    48.0                 17.0       NaN                    2  \n",
       "9                    52.0                 12.0       NaN                    2  \n",
       "13                   65.0                 13.0       NaN                    2  \n",
       "17                   36.0                 22.0       NaN                    1  \n",
       "19                   48.0                 14.0       NaN                    2  \n",
       "...                   ...                  ...       ...                  ...  \n",
       "4106                 48.0                 19.0       NaN                    1  \n",
       "4108                 49.0                 18.0       NaN                    2  \n",
       "4121                 58.0                 12.0       NaN                    1  \n",
       "4123                 47.0                 19.0       NaN                    1  \n",
       "4131                 48.0                 19.0       NaN                    2  \n",
       "\n",
       "[1061 rows x 12 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_talent[df_talent.duplicated(subset=['json_key'],keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Null Values Count  Null Values Percentage\n",
      "name                              0                0.000000\n",
      "trainer                           0                0.000000\n",
      "Analytic_W1                       0                0.000000\n",
      "Independent_W1                    0                0.000000\n",
      "Determined_W1                     0                0.000000\n",
      "...                             ...                     ...\n",
      "Independent_W10                 235               59.193955\n",
      "Determined_W10                  235               59.193955\n",
      "Professional_W10                235               59.193955\n",
      "Studious_W10                    235               59.193955\n",
      "Imaginative_W10                 235               59.193955\n",
      "\n",
      "[64 rows x 2 columns]\n",
      "Duplicate names: []\n",
      "['analytic_w1', 'independent_w1', 'determined_w1', 'professional_w1', 'studious_w1', 'imaginative_w1', 'analytic_w2', 'independent_w2', 'determined_w2', 'professional_w2', 'studious_w2', 'imaginative_w2', 'analytic_w3', 'independent_w3', 'determined_w3', 'professional_w3', 'studious_w3', 'imaginative_w3', 'analytic_w4', 'independent_w4', 'determined_w4', 'professional_w4', 'studious_w4', 'imaginative_w4', 'analytic_w5', 'independent_w5', 'determined_w5', 'professional_w5', 'studious_w5', 'imaginative_w5', 'analytic_w6', 'independent_w6', 'determined_w6', 'professional_w6', 'studious_w6', 'imaginative_w6', 'analytic_w7', 'independent_w7', 'determined_w7', 'professional_w7', 'studious_w7', 'imaginative_w7', 'analytic_w8', 'independent_w8', 'determined_w8', 'professional_w8', 'studious_w8', 'imaginative_w8', 'analytic_w9', 'independent_w9', 'determined_w9', 'professional_w9', 'studious_w9', 'imaginative_w9', 'analytic_w10', 'independent_w10', 'determined_w10', 'professional_w10', 'studious_w10', 'imaginative_w10']\n",
      "    analytic_w1 independent_w1 determined_w1 professional_w1 studious_w1   \n",
      "0             1              2             2               1           2  \\\n",
      "1             6              1             1               2           4   \n",
      "2             6              4             1               1           2   \n",
      "3             2              1             2               3           3   \n",
      "4             2              2             4               5           1   \n",
      "..          ...            ...           ...             ...         ...   \n",
      "392           1              1             5               1           2   \n",
      "393           1              3             3               4           1   \n",
      "394           3              1             2               8           1   \n",
      "395           3              7             3               3           3   \n",
      "396           4              2             5               1           1   \n",
      "\n",
      "    imaginative_w1 analytic_w2 independent_w2 determined_w2 professional_w2   \n",
      "0                2         nan            nan           nan             nan  \\\n",
      "1                2         3.0            1.0           3.0             2.0   \n",
      "2                3         1.0            1.0           1.0             2.0   \n",
      "3                3         4.0            2.0           1.0             3.0   \n",
      "4                2         3.0            2.0           5.0             3.0   \n",
      "..             ...         ...            ...           ...             ...   \n",
      "392              6         5.0            3.0           3.0             3.0   \n",
      "393              2         3.0            3.0           5.0             5.0   \n",
      "394              4         2.0            4.0           3.0             1.0   \n",
      "395              1         2.0            7.0           2.0             3.0   \n",
      "396              2         4.0            1.0           1.0             3.0   \n",
      "\n",
      "    studious_w2 imaginative_w2 analytic_w3 independent_w3 determined_w3   \n",
      "0           nan            nan         nan            nan           nan  \\\n",
      "1           1.0            1.0         nan            nan           nan   \n",
      "2           1.0            6.0         6.0            2.0           2.0   \n",
      "3           3.0            7.0         3.0            5.0           3.0   \n",
      "4           1.0            1.0         3.0            2.0           3.0   \n",
      "..          ...            ...         ...            ...           ...   \n",
      "392         2.0            2.0         3.0            2.0           2.0   \n",
      "393         7.0            1.0         5.0            5.0           1.0   \n",
      "394         3.0            1.0         6.0            2.0           1.0   \n",
      "395         4.0            1.0         1.0            3.0           1.0   \n",
      "396         2.0            5.0         3.0            4.0           1.0   \n",
      "\n",
      "    professional_w3 studious_w3 imaginative_w3 analytic_w4 independent_w4   \n",
      "0               nan         nan            nan         nan            nan  \\\n",
      "1               nan         nan            nan         nan            nan   \n",
      "2               3.0         3.0            2.0         5.0            1.0   \n",
      "3               1.0         3.0            3.0         2.0            8.0   \n",
      "4               4.0         4.0            2.0         8.0            6.0   \n",
      "..              ...         ...            ...         ...            ...   \n",
      "392             3.0         6.0            1.0         8.0            6.0   \n",
      "393             1.0         3.0            3.0         7.0            6.0   \n",
      "394             2.0         3.0            8.0         6.0            8.0   \n",
      "395             2.0         6.0            5.0         4.0            4.0   \n",
      "396             5.0         5.0            3.0         8.0            6.0   \n",
      "\n",
      "    determined_w4 professional_w4 studious_w4 imaginative_w4 analytic_w5   \n",
      "0             nan             nan         nan            nan         nan  \\\n",
      "1             nan             nan         nan            nan         nan   \n",
      "2             3.0             7.0         6.0            2.0         6.0   \n",
      "3             1.0             8.0         5.0            5.0         2.0   \n",
      "4             8.0             2.0         4.0            8.0         6.0   \n",
      "..            ...             ...         ...            ...         ...   \n",
      "392           8.0             5.0         5.0            3.0         6.0   \n",
      "393           5.0             7.0         8.0            8.0         2.0   \n",
      "394           3.0             5.0         8.0            5.0         8.0   \n",
      "395           5.0             3.0         6.0            8.0         4.0   \n",
      "396           5.0             8.0         3.0            8.0         5.0   \n",
      "\n",
      "    independent_w5 determined_w5 professional_w5 studious_w5 imaginative_w5   \n",
      "0              nan           nan             nan         nan            nan  \\\n",
      "1              nan           nan             nan         nan            nan   \n",
      "2              8.0           4.0             8.0         1.0            8.0   \n",
      "3              1.0           8.0             5.0         6.0            5.0   \n",
      "4              2.0           8.0             8.0         8.0            5.0   \n",
      "..             ...           ...             ...         ...            ...   \n",
      "392            8.0           7.0             7.0         4.0            2.0   \n",
      "393            6.0           6.0             8.0         8.0            4.0   \n",
      "394            4.0           6.0             2.0         3.0            2.0   \n",
      "395            3.0           8.0             3.0         8.0            5.0   \n",
      "396            5.0           5.0             7.0         5.0            4.0   \n",
      "\n",
      "    analytic_w6 independent_w6 determined_w6 professional_w6 studious_w6   \n",
      "0           nan            nan           nan             nan         nan  \\\n",
      "1           nan            nan           nan             nan         nan   \n",
      "2           7.0            3.0           5.0             8.0         8.0   \n",
      "3           7.0            6.0           5.0             7.0         8.0   \n",
      "4           7.0            5.0           5.0             5.0         5.0   \n",
      "..          ...            ...           ...             ...         ...   \n",
      "392         7.0            4.0           5.0             7.0         7.0   \n",
      "393         2.0            5.0           4.0             8.0         4.0   \n",
      "394         6.0            8.0           6.0             8.0         7.0   \n",
      "395         5.0            3.0           5.0             6.0         7.0   \n",
      "396         1.0            5.0           4.0             8.0         6.0   \n",
      "\n",
      "    imaginative_w6 analytic_w7 independent_w7 determined_w7 professional_w7   \n",
      "0              nan         nan            nan           nan             nan  \\\n",
      "1              nan         nan            nan           nan             nan   \n",
      "2              7.0         8.0            5.0           8.0             8.0   \n",
      "3              2.0         8.0            6.0           8.0             7.0   \n",
      "4              8.0         8.0            7.0           7.0             8.0   \n",
      "..             ...         ...            ...           ...             ...   \n",
      "392            7.0         6.0            8.0           8.0             7.0   \n",
      "393            6.0         6.0            6.0           8.0             8.0   \n",
      "394            8.0         8.0            3.0           8.0             8.0   \n",
      "395            7.0         8.0            8.0           8.0             8.0   \n",
      "396            8.0         8.0            6.0           8.0             8.0   \n",
      "\n",
      "    studious_w7 imaginative_w7 analytic_w8 independent_w8 determined_w8   \n",
      "0           nan            nan         nan            nan           nan  \\\n",
      "1           nan            nan         nan            nan           nan   \n",
      "2           8.0            6.0         8.0            7.0           8.0   \n",
      "3           8.0            8.0         8.0            8.0           7.0   \n",
      "4           8.0            8.0         8.0            7.0           8.0   \n",
      "..          ...            ...         ...            ...           ...   \n",
      "392         8.0            5.0         4.0            8.0           7.0   \n",
      "393         8.0            8.0         7.0            8.0           5.0   \n",
      "394         4.0            8.0         8.0            8.0           8.0   \n",
      "395         8.0            8.0         8.0            4.0           6.0   \n",
      "396         6.0            8.0         8.0            8.0           8.0   \n",
      "\n",
      "    professional_w8 studious_w8 imaginative_w8 analytic_w9 independent_w9   \n",
      "0               nan         nan            nan         nan            nan  \\\n",
      "1               nan         nan            nan         nan            nan   \n",
      "2               8.0         7.0            8.0         nan            nan   \n",
      "3               8.0         7.0            5.0         nan            nan   \n",
      "4               8.0         8.0            8.0         nan            nan   \n",
      "..              ...         ...            ...         ...            ...   \n",
      "392             8.0         8.0            8.0         nan            nan   \n",
      "393             8.0         8.0            8.0         nan            nan   \n",
      "394             8.0         8.0            5.0         nan            nan   \n",
      "395             8.0         8.0            8.0         nan            nan   \n",
      "396             6.0         6.0            8.0         nan            nan   \n",
      "\n",
      "    determined_w9 professional_w9 studious_w9 imaginative_w9 analytic_w10   \n",
      "0             nan             nan         nan            nan          nan  \\\n",
      "1             nan             nan         nan            nan          nan   \n",
      "2             nan             nan         nan            nan          nan   \n",
      "3             nan             nan         nan            nan          nan   \n",
      "4             nan             nan         nan            nan          nan   \n",
      "..            ...             ...         ...            ...          ...   \n",
      "392           nan             nan         nan            nan          nan   \n",
      "393           nan             nan         nan            nan          nan   \n",
      "394           nan             nan         nan            nan          nan   \n",
      "395           nan             nan         nan            nan          nan   \n",
      "396           nan             nan         nan            nan          nan   \n",
      "\n",
      "    independent_w10 determined_w10 professional_w10 studious_w10   \n",
      "0               nan            nan              nan          nan  \\\n",
      "1               nan            nan              nan          nan   \n",
      "2               nan            nan              nan          nan   \n",
      "3               nan            nan              nan          nan   \n",
      "4               nan            nan              nan          nan   \n",
      "..              ...            ...              ...          ...   \n",
      "392             nan            nan              nan          nan   \n",
      "393             nan            nan              nan          nan   \n",
      "394             nan            nan              nan          nan   \n",
      "395             nan            nan              nan          nan   \n",
      "396             nan            nan              nan          nan   \n",
      "\n",
      "    imaginative_w10  \n",
      "0               nan  \n",
      "1               nan  \n",
      "2               nan  \n",
      "3               nan  \n",
      "4               nan  \n",
      "..              ...  \n",
      "392             nan  \n",
      "393             nan  \n",
      "394             nan  \n",
      "395             nan  \n",
      "396             nan  \n",
      "\n",
      "[397 rows x 60 columns]\n",
      "                  Null Values Count  Null Values Percentage\n",
      "name                              0                0.000000\n",
      "trainer                           0                0.000000\n",
      "Analytic_W1                       0                0.000000\n",
      "Independent_W1                    0                0.000000\n",
      "Determined_W1                     0                0.000000\n",
      "...                             ...                     ...\n",
      "Independent_W10                 235               59.193955\n",
      "Determined_W10                  235               59.193955\n",
      "Professional_W10                235               59.193955\n",
      "Studious_W10                    235               59.193955\n",
      "Imaginative_W10                 235               59.193955\n",
      "\n",
      "[64 rows x 2 columns]\n",
      "Duplicate names: []\n",
      "['analytic_w1', 'independent_w1', 'determined_w1', 'professional_w1', 'studious_w1', 'imaginative_w1', 'analytic_w2', 'independent_w2', 'determined_w2', 'professional_w2', 'studious_w2', 'imaginative_w2', 'analytic_w3', 'independent_w3', 'determined_w3', 'professional_w3', 'studious_w3', 'imaginative_w3', 'analytic_w4', 'independent_w4', 'determined_w4', 'professional_w4', 'studious_w4', 'imaginative_w4', 'analytic_w5', 'independent_w5', 'determined_w5', 'professional_w5', 'studious_w5', 'imaginative_w5', 'analytic_w6', 'independent_w6', 'determined_w6', 'professional_w6', 'studious_w6', 'imaginative_w6', 'analytic_w7', 'independent_w7', 'determined_w7', 'professional_w7', 'studious_w7', 'imaginative_w7', 'analytic_w8', 'independent_w8', 'determined_w8', 'professional_w8', 'studious_w8', 'imaginative_w8', 'analytic_w9', 'independent_w9', 'determined_w9', 'professional_w9', 'studious_w9', 'imaginative_w9', 'analytic_w10', 'independent_w10', 'determined_w10', 'professional_w10', 'studious_w10', 'imaginative_w10']\n",
      "    analytic_w1 independent_w1 determined_w1 professional_w1 studious_w1   \n",
      "0             1              2             2               1           2  \\\n",
      "1             6              1             1               2           4   \n",
      "2             6              4             1               1           2   \n",
      "3             2              1             2               3           3   \n",
      "4             2              2             4               5           1   \n",
      "..          ...            ...           ...             ...         ...   \n",
      "392           1              1             5               1           2   \n",
      "393           1              3             3               4           1   \n",
      "394           3              1             2               8           1   \n",
      "395           3              7             3               3           3   \n",
      "396           4              2             5               1           1   \n",
      "\n",
      "    imaginative_w1 analytic_w2 independent_w2 determined_w2 professional_w2   \n",
      "0                2         nan            nan           nan             nan  \\\n",
      "1                2         3.0            1.0           3.0             2.0   \n",
      "2                3         1.0            1.0           1.0             2.0   \n",
      "3                3         4.0            2.0           1.0             3.0   \n",
      "4                2         3.0            2.0           5.0             3.0   \n",
      "..             ...         ...            ...           ...             ...   \n",
      "392              6         5.0            3.0           3.0             3.0   \n",
      "393              2         3.0            3.0           5.0             5.0   \n",
      "394              4         2.0            4.0           3.0             1.0   \n",
      "395              1         2.0            7.0           2.0             3.0   \n",
      "396              2         4.0            1.0           1.0             3.0   \n",
      "\n",
      "    studious_w2 imaginative_w2 analytic_w3 independent_w3 determined_w3   \n",
      "0           nan            nan         nan            nan           nan  \\\n",
      "1           1.0            1.0         nan            nan           nan   \n",
      "2           1.0            6.0         6.0            2.0           2.0   \n",
      "3           3.0            7.0         3.0            5.0           3.0   \n",
      "4           1.0            1.0         3.0            2.0           3.0   \n",
      "..          ...            ...         ...            ...           ...   \n",
      "392         2.0            2.0         3.0            2.0           2.0   \n",
      "393         7.0            1.0         5.0            5.0           1.0   \n",
      "394         3.0            1.0         6.0            2.0           1.0   \n",
      "395         4.0            1.0         1.0            3.0           1.0   \n",
      "396         2.0            5.0         3.0            4.0           1.0   \n",
      "\n",
      "    professional_w3 studious_w3 imaginative_w3 analytic_w4 independent_w4   \n",
      "0               nan         nan            nan         nan            nan  \\\n",
      "1               nan         nan            nan         nan            nan   \n",
      "2               3.0         3.0            2.0         5.0            1.0   \n",
      "3               1.0         3.0            3.0         2.0            8.0   \n",
      "4               4.0         4.0            2.0         8.0            6.0   \n",
      "..              ...         ...            ...         ...            ...   \n",
      "392             3.0         6.0            1.0         8.0            6.0   \n",
      "393             1.0         3.0            3.0         7.0            6.0   \n",
      "394             2.0         3.0            8.0         6.0            8.0   \n",
      "395             2.0         6.0            5.0         4.0            4.0   \n",
      "396             5.0         5.0            3.0         8.0            6.0   \n",
      "\n",
      "    determined_w4 professional_w4 studious_w4 imaginative_w4 analytic_w5   \n",
      "0             nan             nan         nan            nan         nan  \\\n",
      "1             nan             nan         nan            nan         nan   \n",
      "2             3.0             7.0         6.0            2.0         6.0   \n",
      "3             1.0             8.0         5.0            5.0         2.0   \n",
      "4             8.0             2.0         4.0            8.0         6.0   \n",
      "..            ...             ...         ...            ...         ...   \n",
      "392           8.0             5.0         5.0            3.0         6.0   \n",
      "393           5.0             7.0         8.0            8.0         2.0   \n",
      "394           3.0             5.0         8.0            5.0         8.0   \n",
      "395           5.0             3.0         6.0            8.0         4.0   \n",
      "396           5.0             8.0         3.0            8.0         5.0   \n",
      "\n",
      "    independent_w5 determined_w5 professional_w5 studious_w5 imaginative_w5   \n",
      "0              nan           nan             nan         nan            nan  \\\n",
      "1              nan           nan             nan         nan            nan   \n",
      "2              8.0           4.0             8.0         1.0            8.0   \n",
      "3              1.0           8.0             5.0         6.0            5.0   \n",
      "4              2.0           8.0             8.0         8.0            5.0   \n",
      "..             ...           ...             ...         ...            ...   \n",
      "392            8.0           7.0             7.0         4.0            2.0   \n",
      "393            6.0           6.0             8.0         8.0            4.0   \n",
      "394            4.0           6.0             2.0         3.0            2.0   \n",
      "395            3.0           8.0             3.0         8.0            5.0   \n",
      "396            5.0           5.0             7.0         5.0            4.0   \n",
      "\n",
      "    analytic_w6 independent_w6 determined_w6 professional_w6 studious_w6   \n",
      "0           nan            nan           nan             nan         nan  \\\n",
      "1           nan            nan           nan             nan         nan   \n",
      "2           7.0            3.0           5.0             8.0         8.0   \n",
      "3           7.0            6.0           5.0             7.0         8.0   \n",
      "4           7.0            5.0           5.0             5.0         5.0   \n",
      "..          ...            ...           ...             ...         ...   \n",
      "392         7.0            4.0           5.0             7.0         7.0   \n",
      "393         2.0            5.0           4.0             8.0         4.0   \n",
      "394         6.0            8.0           6.0             8.0         7.0   \n",
      "395         5.0            3.0           5.0             6.0         7.0   \n",
      "396         1.0            5.0           4.0             8.0         6.0   \n",
      "\n",
      "    imaginative_w6 analytic_w7 independent_w7 determined_w7 professional_w7   \n",
      "0              nan         nan            nan           nan             nan  \\\n",
      "1              nan         nan            nan           nan             nan   \n",
      "2              7.0         8.0            5.0           8.0             8.0   \n",
      "3              2.0         8.0            6.0           8.0             7.0   \n",
      "4              8.0         8.0            7.0           7.0             8.0   \n",
      "..             ...         ...            ...           ...             ...   \n",
      "392            7.0         6.0            8.0           8.0             7.0   \n",
      "393            6.0         6.0            6.0           8.0             8.0   \n",
      "394            8.0         8.0            3.0           8.0             8.0   \n",
      "395            7.0         8.0            8.0           8.0             8.0   \n",
      "396            8.0         8.0            6.0           8.0             8.0   \n",
      "\n",
      "    studious_w7 imaginative_w7 analytic_w8 independent_w8 determined_w8   \n",
      "0           nan            nan         nan            nan           nan  \\\n",
      "1           nan            nan         nan            nan           nan   \n",
      "2           8.0            6.0         8.0            7.0           8.0   \n",
      "3           8.0            8.0         8.0            8.0           7.0   \n",
      "4           8.0            8.0         8.0            7.0           8.0   \n",
      "..          ...            ...         ...            ...           ...   \n",
      "392         8.0            5.0         4.0            8.0           7.0   \n",
      "393         8.0            8.0         7.0            8.0           5.0   \n",
      "394         4.0            8.0         8.0            8.0           8.0   \n",
      "395         8.0            8.0         8.0            4.0           6.0   \n",
      "396         6.0            8.0         8.0            8.0           8.0   \n",
      "\n",
      "    professional_w8 studious_w8 imaginative_w8 analytic_w9 independent_w9   \n",
      "0               nan         nan            nan         nan            nan  \\\n",
      "1               nan         nan            nan         nan            nan   \n",
      "2               8.0         7.0            8.0         nan            nan   \n",
      "3               8.0         7.0            5.0         nan            nan   \n",
      "4               8.0         8.0            8.0         nan            nan   \n",
      "..              ...         ...            ...         ...            ...   \n",
      "392             8.0         8.0            8.0         nan            nan   \n",
      "393             8.0         8.0            8.0         nan            nan   \n",
      "394             8.0         8.0            5.0         nan            nan   \n",
      "395             8.0         8.0            8.0         nan            nan   \n",
      "396             6.0         6.0            8.0         nan            nan   \n",
      "\n",
      "    determined_w9 professional_w9 studious_w9 imaginative_w9 analytic_w10   \n",
      "0             nan             nan         nan            nan          nan  \\\n",
      "1             nan             nan         nan            nan          nan   \n",
      "2             nan             nan         nan            nan          nan   \n",
      "3             nan             nan         nan            nan          nan   \n",
      "4             nan             nan         nan            nan          nan   \n",
      "..            ...             ...         ...            ...          ...   \n",
      "392           nan             nan         nan            nan          nan   \n",
      "393           nan             nan         nan            nan          nan   \n",
      "394           nan             nan         nan            nan          nan   \n",
      "395           nan             nan         nan            nan          nan   \n",
      "396           nan             nan         nan            nan          nan   \n",
      "\n",
      "    independent_w10 determined_w10 professional_w10 studious_w10   \n",
      "0               nan            nan              nan          nan  \\\n",
      "1               nan            nan              nan          nan   \n",
      "2               nan            nan              nan          nan   \n",
      "3               nan            nan              nan          nan   \n",
      "4               nan            nan              nan          nan   \n",
      "..              ...            ...              ...          ...   \n",
      "392             nan            nan              nan          nan   \n",
      "393             nan            nan              nan          nan   \n",
      "394             nan            nan              nan          nan   \n",
      "395             nan            nan              nan          nan   \n",
      "396             nan            nan              nan          nan   \n",
      "\n",
      "    imaginative_w10  \n",
      "0               nan  \n",
      "1               nan  \n",
      "2               nan  \n",
      "3               nan  \n",
      "4               nan  \n",
      "..              ...  \n",
      "392             nan  \n",
      "393             nan  \n",
      "394             nan  \n",
      "395             nan  \n",
      "396             nan  \n",
      "\n",
      "[397 rows x 60 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'academy_behaviours' from 'D:\\\\Sparta\\\\final_project\\\\data210-final-project\\\\Scripts\\\\academy_behaviours.py'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import academy_behaviours\n",
    "importlib.reload(academy_behaviours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_courses = academy_behaviours.course.copy()\n",
    "df_courses = df_courses.drop_duplicates().reset_index(drop=True)\n",
    "df_trainers = academy_behaviours.trainer.copy()\n",
    "df_trainers = df_trainers.drop_duplicates().reset_index(drop=True)\n",
    "df_spartans = academy_behaviours.spartans.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>behaviour_id</th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>trainer_id</th>\n",
       "      <th>course_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [behaviour_id, name, date, trainer_id, course_id]\n",
       "Index: []"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spartans[~df_spartans['name'].isin(df_talent.dropna(subset='json_key',axis=0)['name'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need course names to match people and link to talent\n",
    "df_spartans['course_name'] = df_spartans['course_id'].replace(df_courses.course_id.tolist(),df_courses.course_name.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_behaviours = academy_behaviours.behaviour.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method to add the applicant ID from Talents to Spartans by matching nearest course\n",
    "def addApplicantID(talent_record):\n",
    "     # if talent_record['date'].isna():\n",
    "     #      return\n",
    "     result = df_spartans[(df_spartans['name'] == talent_record['name']) & (df_spartans['course_name'] == talent_record['course_interest']) &\n",
    "                ((df_spartans['date'] >= talent_record['date']) | (pd.isnull(talent_record['date'])))].sort_values(by='date',axis=0,ascending=True)\n",
    "     if not result.empty:\n",
    "          df_spartans.at[result.index[0],'json_key'] = talent_record['json_key']\n",
    "          #print(talent_record['json_key'])\n",
    "          #print(result.index[0])\n",
    "#Do for every row in talent\n",
    "for index, row in df_talent.iterrows():\n",
    "    addApplicantID(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spartans.json_key.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['course_id', 'course_name'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course_id</th>\n",
       "      <th>course_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BUS</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DAT</td>\n",
       "      <td>Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENG</td>\n",
       "      <td>Engineering</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  course_id  course_name\n",
       "0       BUS     Business\n",
       "1       DAT         Data\n",
       "2       ENG  Engineering"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with engine.connect() as conn:\n",
    "    result = pd.read_sql(text(\"SELECT * FROM Courses\"),conn)\n",
    "    print(result.columns)\n",
    "    display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_talent),len(df_applicants))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>applicant_id</th>\n",
       "      <th>json_key</th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>self_development</th>\n",
       "      <th>financial_support_self</th>\n",
       "      <th>result</th>\n",
       "      <th>course_interest</th>\n",
       "      <th>psychometric_result</th>\n",
       "      <th>presentation_result</th>\n",
       "      <th>geo_flex</th>\n",
       "      <th>academy_location_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [applicant_id, json_key, name, date, self_development, financial_support_self, result, course_interest, psychometric_result, presentation_result, geo_flex, academy_location_id]\n",
       "Index: []"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_talent = df_talent.groupby(['applicant_id'], as_index=False).first()\n",
    "df_talent[df_talent.duplicated(subset=\"applicant_id\",keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>dob</th>\n",
       "      <th>email</th>\n",
       "      <th>phone_number</th>\n",
       "      <th>uni</th>\n",
       "      <th>degree</th>\n",
       "      <th>invited_date</th>\n",
       "      <th>iddate</th>\n",
       "      <th>applicant_id</th>\n",
       "      <th>recruiter_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eryn Speers</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaT</td>\n",
       "      <td>espeers3@shinystat.com</td>\n",
       "      <td>+44-148-787-0613</td>\n",
       "      <td>University of Edinburgh</td>\n",
       "      <td>2:1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>20190400</td>\n",
       "      <td>erynspeers20190400</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Carlen Kemell</td>\n",
       "      <td>Female</td>\n",
       "      <td>1997-03-30</td>\n",
       "      <td>ckemellb@theglobeandmail.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>University of Halifax, Birmingham Campus</td>\n",
       "      <td>2:1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>20190400</td>\n",
       "      <td>carlenkemell20190400</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Kristien Down</td>\n",
       "      <td>Female</td>\n",
       "      <td>1998-09-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>+44-515-630-5818</td>\n",
       "      <td>The Queen's University Belfast</td>\n",
       "      <td>2:1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>20190400</td>\n",
       "      <td>kristiendown20190400</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Zoe Silver</td>\n",
       "      <td>Female</td>\n",
       "      <td>1993-04-07</td>\n",
       "      <td>zsilveru@artisteer.com</td>\n",
       "      <td>+44-563-661-1984</td>\n",
       "      <td>University of Liverpool</td>\n",
       "      <td>2:1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>20190400</td>\n",
       "      <td>zoesilver20190400</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Stuart Birnie</td>\n",
       "      <td>Male</td>\n",
       "      <td>1998-09-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>University of Plymouth</td>\n",
       "      <td>2:2</td>\n",
       "      <td>NaT</td>\n",
       "      <td>20190400</td>\n",
       "      <td>stuartbirnie20190400</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>Quincey Matuszyk</td>\n",
       "      <td>Male</td>\n",
       "      <td>1999-03-03</td>\n",
       "      <td>qmatuszyk9o@ebay.co.uk</td>\n",
       "      <td>+44-121-796-8376</td>\n",
       "      <td>Leeds Metropolitan University</td>\n",
       "      <td>3rd</td>\n",
       "      <td>NaT</td>\n",
       "      <td>20190900</td>\n",
       "      <td>quinceymatuszyk20190900</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>Winni Bason</td>\n",
       "      <td>Female</td>\n",
       "      <td>1990-04-10</td>\n",
       "      <td>wbasonae@answers.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>University of Birmingham</td>\n",
       "      <td>2:2</td>\n",
       "      <td>NaT</td>\n",
       "      <td>20190900</td>\n",
       "      <td>winnibason20190900</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>Ninetta Garling</td>\n",
       "      <td>Female</td>\n",
       "      <td>1990-09-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>+44-958-122-8728</td>\n",
       "      <td>Leeds Metropolitan University</td>\n",
       "      <td>2:1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>20190900</td>\n",
       "      <td>ninettagarling20190900</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>Hastings Fincher</td>\n",
       "      <td>Male</td>\n",
       "      <td>1995-01-22</td>\n",
       "      <td>hfincherb5@weebly.com</td>\n",
       "      <td>+44-348-361-7341</td>\n",
       "      <td>Institute of Education, University of London</td>\n",
       "      <td>2:2</td>\n",
       "      <td>NaT</td>\n",
       "      <td>20190900</td>\n",
       "      <td>hastingsfincher20190900</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>Claudia Feldhuhn</td>\n",
       "      <td>Female</td>\n",
       "      <td>1997-05-14</td>\n",
       "      <td>cfeldhuhnbd@psu.edu</td>\n",
       "      <td>+44-770-742-9595</td>\n",
       "      <td>University of Ulster</td>\n",
       "      <td>2:1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>20190900</td>\n",
       "      <td>claudiafeldhuhn20190900</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>557 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 name  gender        dob                         email   \n",
       "3         Eryn Speers  Female        NaT        espeers3@shinystat.com  \\\n",
       "11      Carlen Kemell  Female 1997-03-30  ckemellb@theglobeandmail.com   \n",
       "26      Kristien Down  Female 1998-09-11                           NaN   \n",
       "30         Zoe Silver  Female 1993-04-07        zsilveru@artisteer.com   \n",
       "32      Stuart Birnie    Male 1998-09-09                           NaN   \n",
       "..                ...     ...        ...                           ...   \n",
       "348  Quincey Matuszyk    Male 1999-03-03        qmatuszyk9o@ebay.co.uk   \n",
       "374       Winni Bason  Female 1990-04-10          wbasonae@answers.com   \n",
       "383   Ninetta Garling  Female 1990-09-29                           NaN   \n",
       "401  Hastings Fincher    Male 1995-01-22         hfincherb5@weebly.com   \n",
       "409  Claudia Feldhuhn  Female 1997-05-14           cfeldhuhnbd@psu.edu   \n",
       "\n",
       "         phone_number                                           uni degree   \n",
       "3    +44-148-787-0613                       University of Edinburgh    2:1  \\\n",
       "11                NaN      University of Halifax, Birmingham Campus    2:1   \n",
       "26   +44-515-630-5818                The Queen's University Belfast    2:1   \n",
       "30   +44-563-661-1984                       University of Liverpool    2:1   \n",
       "32                NaN                        University of Plymouth    2:2   \n",
       "..                ...                                           ...    ...   \n",
       "348  +44-121-796-8376                 Leeds Metropolitan University    3rd   \n",
       "374               NaN                      University of Birmingham    2:2   \n",
       "383  +44-958-122-8728                 Leeds Metropolitan University    2:1   \n",
       "401  +44-348-361-7341  Institute of Education, University of London    2:2   \n",
       "409  +44-770-742-9595                          University of Ulster    2:1   \n",
       "\n",
       "    invited_date    iddate             applicant_id  recruiter_id  \n",
       "3            NaT  20190400       erynspeers20190400             4  \n",
       "11           NaT  20190400     carlenkemell20190400             4  \n",
       "26           NaT  20190400     kristiendown20190400             4  \n",
       "30           NaT  20190400        zoesilver20190400             4  \n",
       "32           NaT  20190400     stuartbirnie20190400             4  \n",
       "..           ...       ...                      ...           ...  \n",
       "348          NaT  20190900  quinceymatuszyk20190900             4  \n",
       "374          NaT  20190900       winnibason20190900             4  \n",
       "383          NaT  20190900   ninettagarling20190900             4  \n",
       "401          NaT  20190900  hastingsfincher20190900             4  \n",
       "409          NaT  20190900  claudiafeldhuhn20190900             4  \n",
       "\n",
       "[557 rows x 11 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_applicants[~df_applicants['applicant_id'].isin(df_talent['applicant_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Recruiters table - NO DEPENDENCIES\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(\"SET IDENTITY_INSERT Recruiters ON\"))\n",
    "    result = df_recruiters.to_sql('Recruiters',conn,if_exists='append',index=False)\n",
    "    conn.execute(text(\"SET IDENTITY_INSERT Recruiters OFF\"))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Applicants table - DEPENDS ON Recruiters\n",
    "with engine.connect() as conn:\n",
    "    #conn.execute(text(\"SET IDENTITY_INSERT Applicants ON\"))\n",
    "    result = df_applicants.drop([\"iddate\"],axis=1).to_sql('Applicants',conn,if_exists='append',index=False)\n",
    "    #conn.execute(text(\"SET IDENTITY_INSERT Applicants OFF\"))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Academy_Locations table - NO DEPENDENCIES\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(\"SET IDENTITY_INSERT Strengths OFF\"))\n",
    "    conn.execute(text(\"SET IDENTITY_INSERT Academy_Locations ON\"))\n",
    "    result = df_academy_locations.to_sql('Academy_Locations',conn,if_exists='append',index=False)\n",
    "    conn.execute(text(\"SET IDENTITY_INSERT Academy_Locations OFF\"))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Talent table - DEPENDS ON Academy_Locations AND Applicants\n",
    "# import numpy as np\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    # conn.execute(text(\"SET IDENTITY_INSERT Talent ON\"))\n",
    "    result = df_talent.drop(['name'], axis=1).dropna(subset=\"json_key\",axis=0).to_sql('Talent',conn,if_exists='append',index=False)\n",
    "    # conn.execute(text(\"SET IDENTITY_INSERT Talent OFF\"))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>json_key</th>\n",
       "      <th>strength_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [json_key, strength_id]\n",
       "Index: []"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_strengths_junction[~df_strengths_junction['strength_id'].isin(df_strengths['strength_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Strengths table - NO DEPENDENCIES\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(\"SET IDENTITY_INSERT Strengths ON\"))\n",
    "    result = df_strengths.to_sql('Strengths',conn,if_exists='append',index=False)\n",
    "    conn.execute(text(\"SET IDENTITY_INSERT Strengths OFF\"))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Weaknesses table - NO DEPENDENCIES\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(\"SET IDENTITY_INSERT Strengths OFF\"))\n",
    "    conn.execute(text(\"SET IDENTITY_INSERT Weaknesses ON\"))\n",
    "    result = df_weaknesses.to_sql('Weaknesses',conn,if_exists='append',index=False)\n",
    "    conn.execute(text(\"SET IDENTITY_INSERT Weaknesses OFF\"))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Tech_Self_Scores table - NO DEPENDENCIES\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(\"SET IDENTITY_INSERT Tech_Self_Scores ON\"))\n",
    "    result = df_tech_self_scores.to_sql('Tech_Self_Scores',conn,if_exists='append',index=False)\n",
    "    conn.execute(text(\"SET IDENTITY_INSERT Tech_Self_Scores OFF\"))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have to eliminate leftover duplicates from people with repeated .jsons - this doesnt actually lose any data\n",
    "df_strengths_junction = df_strengths_junction.drop(index = df_strengths_junction[~df_strengths_junction['json_key'].isin(df_talent['json_key'])].index)\n",
    "df_weaknesses_junction = df_weaknesses_junction.drop(index = df_weaknesses_junction[~df_weaknesses_junction['json_key'].isin(df_talent['json_key'])].index)\n",
    "df_tech_junction = df_tech_junction.drop(index=df_tech_junction[~df_tech_junction['json_key'].astype('float').isin(df_talent['json_key'])].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>json_key</th>\n",
       "      <th>strength_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [json_key, strength_id]\n",
       "Index: []"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_strengths_junction[~df_strengths_junction['json_key'].isin(df_talent['json_key'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Strengths_Junction table - DEPENDS ON Strengths_Junction AND Talent\n",
    "with engine.connect() as conn:\n",
    "    # conn.execute(text(\"SET IDENTITY_INSERT Weaknesses_junction ON\"))\n",
    "    result = df_strengths_junction.to_sql('Strengths_Junction',conn,if_exists='append',index=False)\n",
    "    # conn.execute(text(\"SET IDENTITY_INSERT Weaknesses_junction OFF\"))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Weaknesses_Junction table - DEPENDS ON Weaknesses AND Talent\n",
    "with engine.connect() as conn:\n",
    "    # conn.execute(text(\"SET IDENTITY_INSERT Weaknesses_junction ON\"))\n",
    "    result = df_weaknesses_junction.to_sql('Weaknesses_Junction',conn,if_exists='append',index=False)\n",
    "    # conn.execute(text(\"SET IDENTITY_INSERT Weaknesses_junction OFF\"))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Tech_Junction table - DEPENDS ON Weaknesses AND Talent\n",
    "with engine.connect() as conn:\n",
    "    # conn.execute(text(\"SET IDENTITY_INSERT Tech_Junction ON\"))\n",
    "    result = df_tech_junction.to_sql('Tech_Junction',conn,if_exists='append',index=False)\n",
    "    # conn.execute(text(\"SET IDENTITY_INSERT Tech_Junction OFF\"))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Location table - DEPENDS ON Applicants\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(\"SET IDENTITY_INSERT Location ON\"))\n",
    "    result = df_location.to_sql('Location',conn,if_exists='append',index=False)\n",
    "    conn.execute(text(\"SET IDENTITY_INSERT Location OFF\"))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_talent = df_talent.drop(index = df_talent[~df_talent['applicant_id'].isin(df_applicants['applicant_id'])].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Courses table - NO DEPENDENCIES\n",
    "with engine.connect() as conn:\n",
    "    #conn.execute(text(\"SET IDENTITY_INSERT Courses ON\"))\n",
    "    result = df_courses.to_sql('Courses',conn,if_exists='append',index=False)\n",
    "    #conn.execute(text(\"SET IDENTITY_INSERT Courses OFF\"))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Trainers table - NO DEPENDENCIES\n",
    "with engine.connect() as conn:\n",
    "    #conn.execute(text(\"SET IDENTITY_INSERT Trainers ON\"))\n",
    "    df_trainers.to_sql('Trainers',conn,if_exists='append',index=False)\n",
    "    #conn.execute(text(\"SET IDENTITY_INSERT Trainers OFF\"))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>behaviour_id</th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>trainer_id</th>\n",
       "      <th>course_id</th>\n",
       "      <th>course_name</th>\n",
       "      <th>json_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [behaviour_id, name, date, trainer_id, course_id, course_name, json_key]\n",
       "Index: []"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Somehow theres records with a json_key but not the details that go with it?\n",
    "#This was \"fixed\" in the linking method by linking by name only if date is missing\n",
    "df_spartans[df_spartans.json_key.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Spartans table - DEPENDS ON Courses AND Tables\n",
    "with engine.connect() as conn:\n",
    "    df_spartans.drop(['behaviour_id','name','course_name','date'],axis=1).to_sql('Spartans',conn,if_exists='append',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to query database for auto-generated spartan ids, merge behaviours so that we can extract the sparta_id into behaviour records\n",
    "with engine.connect() as conn:\n",
    "    df_spartans_temp = pd.read_sql(text(\"SELECT * FROM Spartans\"), conn)\n",
    "    df_behaviours_insert = pd.merge(df_behaviours, pd.merge(df_spartans, df_spartans_temp, on='json_key')[\n",
    "        ['behaviour_id', 'spartan_id']], on='behaviour_id').drop(['behaviour_id', 'name'], axis=1).rename(columns={'week': 'week_number'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Behaviours table - DEPENDS ON Spartans\n",
    "with engine.connect() as conn:\n",
    "    # conn.execute(text(\"SET IDENTITY_INSERT Behaviours ON\"))\n",
    "    df_behaviours_insert.to_sql('Behaviours', conn, if_exists='append', index=False)\n",
    "    # conn.execute(text(\"SET IDENTITY_INSERT Behaviours OFF\"))\n",
    "    conn.commit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
